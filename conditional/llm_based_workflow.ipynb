{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ad6a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "457a859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\"]= Field(description=\"Provide the sentiment of the review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e12bc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eac5a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm= HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token= os.getenv(\"HUGGINGFACE_API_ENDPOINT\"),\n",
    "    max_new_tokens= 500,\n",
    "    temperature= 0.3\n",
    ")\n",
    "\n",
    "model= ChatHuggingFace(llm= llm)\n",
    "\n",
    "parser1= PydanticOutputParser(pydantic_object=SentimentSchema)\n",
    "parser2= PydanticOutputParser(pydantic_object= DiagnosisSchema)\n",
    "\n",
    "def getPrompt(review: str)-> str :\n",
    "    prompt= PromptTemplate(\n",
    "        # template= \"Find the sentiment of the review {review} and the output should be strictly in the given format and it should not contain anything else except for the values present in the object:{format_instructions}\",\n",
    "        template= \"\"\"\n",
    "        You are a sentiment classifier.\n",
    "        Analyze the following review and return the sentiment as JSON.\n",
    "\n",
    "        Rules:\n",
    "        - Sentiment must be exactly one of: \"positive\" or \"negative\".\n",
    "        - Respond ONLY with valid JSON.\n",
    "        - Do not include any text outside the JSON.\n",
    "\n",
    "        Example output:\n",
    "        {{\"sentiment\": \"positive\"}}\n",
    "\n",
    "        Review: {review}\n",
    "        \"\"\",\n",
    "        input_variables=[\"review\"],\n",
    "        partial_variables={\"format_instructions\": parser1.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    return prompt.format(review= review)\n",
    "\n",
    "def getDiagnosisPrompt(review: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt for classifying a negative review using DiagnosisSchema.\n",
    "    Uses parser2 to enforce JSON format.\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a customer support analyst AI.\n",
    "        Analyze the following negative review and return a diagnosis as JSON.\n",
    "\n",
    "        Rules:\n",
    "        - issue_type must be exactly one of: \"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\".\n",
    "        - tone must be exactly one of: \"angry\", \"frustrated\", \"disappointed\", \"calm\".\n",
    "        - urgency must be exactly one of: \"low\", \"medium\", \"high\".\n",
    "        - Respond ONLY with valid JSON.\n",
    "        - Do not include any text outside the JSON.\n",
    "\n",
    "        Example output:\n",
    "        {{\"issue_type\": \"Performance\", \"tone\": \"frustrated\", \"urgency\": \"high\"}}\n",
    "\n",
    "        Review: {review}\n",
    "        \"\"\",\n",
    "        input_variables=[\"review\"],\n",
    "        partial_variables={\"format_instructions\": parser2.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    return prompt.format(review=review)\n",
    "    \n",
    "\n",
    "chain1= model | parser1\n",
    "chain2= model | parser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bfdd57ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment='positive'\n"
     ]
    }
   ],
   "source": [
    "output= chain1.invoke(getPrompt(\"This is the best product I have seen in my entire life\"))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17dd7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "    # diagnosis: {\"issue_type\", \"tone\", \"urgency\"}\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1275e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state:ReviewState)-> ReviewState:\n",
    "    review= state['review']\n",
    "    sentiment= chain1.invoke(getPrompt(review)).sentiment\n",
    "    \n",
    "    return {\"sentiment\":sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e20b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSentiment(state:ReviewState)-> Literal[\"run_diagnosis\", \"positive_response\"]:\n",
    "    if state['sentiment']== 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aea9b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_response(state:ReviewState)-> ReviewState:\n",
    "    prompt= f\"Write a warm response for the given positive response: {state['review']}. Also ask the user to leave the feedback on the website\"\n",
    "    \n",
    "    response= model.invoke(prompt).content\n",
    "    \n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fc438fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_diagnosis(state:ReviewState)-> ReviewState:\n",
    "    response= chain2.invoke(getDiagnosisPrompt(state['review']))\n",
    "    \n",
    "    return {\"diagnosis\": response.model_dump()} # model dump is used to convert the json object into the dict\n",
    "\n",
    "def negative_response(state: ReviewState)-> ReviewState:\n",
    "    diagnosis= state['diagnosis']\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response= model.invoke(prompt).content\n",
    "    \n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "039ab220",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment', checkSentiment)\n",
    "\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "\n",
    "graph.add_edge('positive_response', END)\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow= graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a88d81be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': 'I LG Ultragear 32 inch monitor but it is not working properly. I am very much disappointed and not having any trust on this company. I will not suggest anyone to purchase from LG', 'sentiment': 'negative', 'diagnosis': {'issue_type': 'Performance', 'tone': 'disappointed', 'urgency': 'high'}, 'response': \"Dear [User's Name],\\n\\nI want to start by apologizing for the 'Performance' issue that you encountered, and I'm truly sorry that it caused you disappointment. I can imagine how frustrating it must be when something doesn't work as expected, especially when you mark it as 'high' urgency.\\n\\nI've investigated the matter, and I'm happy to inform you that we've taken immediate action to resolve the issue. Our team has been working diligently to address the problem, and we've implemented a solution that should significantly improve the performance of the system.\\n\\nTo ensure a smooth experience for you, I'd like to offer the following:\\n\\n1. A temporary workaround has been implemented to minimize any disruption.\\n2. Our development team is continuing to work on a permanent fix, which should be rolled out within the next [timeframe, e.g., 24-48 hours].\\n3. In the meantime, I'm here to assist you with any questions or concerns you may have, and I'll do my best to provide updates on the progress.\\n\\nIf you have any further issues or concerns, please don't hesitate to reach out to me directly. Your satisfaction is our top priority, and I'm committed to ensuring that you receive the support you need.\\n\\nThank you for bringing this issue to our attention, and I look forward to hearing from you soon.\\n\\nBest regards,\\n[Your Name]\\nSupport Assistant\"}\n"
     ]
    }
   ],
   "source": [
    "initial_state={\"review\":\"I LG Ultragear 32 inch monitor but it is not working properly. I am very much disappointed and not having any trust on this company. I will not suggest anyone to purchase from LG\"}\n",
    "final_state= workflow.invoke(initial_state)\n",
    "\n",
    "print(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
